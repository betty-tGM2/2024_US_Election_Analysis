---
title: "2024 US Election Prediction"
subtitle: "An Analysis of Donald Trump’s Polling Trends and Predictive Outcomes"
author: 
  - Betty Liu
  - Jingchuan Xu
  - Dingshuo Li
thanks: "Code and data are available at: https://github.com/dawsonlll/2024_US_Election_Analysis"
date: Nov 04, 2024
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: true
#| message: false

library(tidyverse)
library(modelsummary)
library(palmerpenguins)
library(ggplot2)
library(arrow)
library(here)
library(modelr)
library(knitr)
library(rstanarm)
opts_knit$set(root.dir = here::here())

setwd(here::here())
trump_analysis_data <- read_parquet("data/02-analysis_data/analysis_trump_data.parquet")
harris_analysis_data <- read_parquet("data/02-analysis_data/analysis_harris_data.parquet")

```


# Introduction

The 2024 U.S. presidential election is one of the most closely watched events in recent political history. Polling provides a glimpse into the dynamics of the race, offering insights that can shape campaign strategies and public opinion. Among the candidates, former President Donald Trump consistently draws significant attention and debate from the public across different political perspectives. Tracking Trump’s support through the poll reveals his current popularity and potential electoral outcomes. 
The paper dives into Trump’s polling data, analyzing data from various pollsters to see how his support has changed over time. The study explores whether there is an upward or downward trend using linear modelling in Trump’s polling percentage, while also accounting for differences in his support reported by various pollsters. By investigating these patterns, the analysis aims to estimate Trump’s likely level of support as election day approaches. 

Estimand: The estimand of this study is the expected level of voter support for Donald Trump in the 2024 U.S. presidential election, based on observed patterns in polling data. This estimated support level provides a snapshot of his projected standing among voters with the adjective by pollster-specific effects.  

In this study, we apply statistical models, including a linear model of Trump's percentage over time, to quantify changes in his support level. Additionally, we adjust for pollster variations to provide a more accurate reflection of his support trajectory across different sources. Our findings reveal both temporal trends and variability among pollsters, highlighting the complexities of interpreting polling data in a polarized political environment. These insights contribute to a better understanding of Trump’s standing and the potential outcomes in 2024. 

The remainder of the paper is structured as follows: @sec-data outlines the dataset selection and cleaning process to ensure transparency in data preparation. @sec-model introduces the model used, explaining its components with clear notation and connecting modeling decisions to the data section with focusing on linear models and pollster-specific adjustments.  @sec-result presents the results of the analysis, including both temporal and cross-pollster trends in Trump’s support. Finally, @sec-discussion interprets the results, and @sec-limitation addresses study limitations and future research directions.





# Data {#sec-data}

## Overview

The dataset, sourced from @polls, compiles polling data from multiple pollsters who applied various methodologies—such as online panels, live phone surveys, and text-to-web approaches—to gauge voter support for presidential candidates in the 2024 U.S. election. Each entry captures a distinct polling event, with details on the pollster, methodology, sample size, and public support percentages for each candidate, specifically focusing on the public’s stance toward Donald Trump following his declaration to run for president. This dataset provides a snapshot of public opinion across different pollsters, methodologies, and timeframes, offering insights into the shifting landscape of voter sentiment.

All data analysis was conducted using R @citeR, including statistical computing and graphics. And the following R packages were used: tidyverse @tidy, Palmerpenguins @palmerpenguins, ggplot2 @ggplot2, Dplyr @citedplyr, Knitr @citeknitr, modelsummary @modelsummary, arrow @arrow, and here @here. Following  @tellingstories we conducted data simulate, test simulated data, data cleanning, test analysis data, EDA, data modelling. The R code in scripts were adapted from @alexander2023telling

For accuracy and relevance, we filtered the data to include only polls conducted by high-quality pollsters with a numeric grade greater than 2.7. This threshold ensures that the dataset primarily represents credible polls, aligning with industry standards for reliability and transparency. Additionally, we factored in only polls conducted after Trump and Harris' 2024 presidential campaign announcement, allowing a focused analysis of his support trajectory post-announcement. Through these data selection and cleaning criteria, the dataset provides a high-quality, methodologically consistent foundation for examining voter support trends for Trump and Harris in the 2024 election.


## Measurement
The measurement approach in this dataset translates real-world polling events into structured data entries, capturing shifts in public opinion on presidential candidates. Each entry represents a specific poll by a polling organization, providing a snapshot of support levels for the 2024 U.S. presidential election. Polls are conducted through varied methodologies—such as online panels and live phone surveys—which can impact reliability. Polls are sponsored by institutions like news organizations, with the pollster and sponsor information recorded for transparency and credibility.

Key columns include poll scores and candidate-specific percentages, translating public sentiment into measurable values that reflect candidates’ standings over time. Sample size and population type  give insight into the scope of each poll, helping to contextualize its representativeness. Temporal data, such as start and end dates, allow us to analyze trends over time, correlating shifts in support with major events.

Together, these components ensure each dataset entry reflects a distinct polling event, with variables like pollster reputation and methodology contributing to an accurate picture of public sentiment. This structured framework enables reliable trend analysis, supporting meaningful insights into polling data for presidential candidates.


## Outcome variables
The primary outcome variable in this dataset is the approval rating (pct), which represents the percentage of poll respondents who support Donald Trump as a presidential candidate. This variable provides insight into Trump's popularity over time, helping to reveal changes in public sentiment across states and voting periods. The summary of table for both Trump and Harris can be observed @tbl-pct.
```{r}
#| label: tbl-pct
#| tbl-cap: "Preview of Summary Statistics for Trump and Harris"
#| echo: false
#| warning: false
#| message: false

# Calculate summary statistics for Trump
trump_summary <- trump_analysis_data %>%
  summarise(
    Candidate = "Trump",
    mean_pct = mean(pct, na.rm = TRUE),
    median_pct = median(pct, na.rm = TRUE),
    min_pct = min(pct, na.rm = TRUE),
    max_pct = max(pct, na.rm = TRUE),
    sd_pct = sd(pct, na.rm = TRUE)
  )

# Calculate summary statistics for Harris
harris_summary <- harris_analysis_data %>%
  summarise(
    Candidate = "Harris",
    mean_pct = mean(pct, na.rm = TRUE),
    median_pct = median(pct, na.rm = TRUE),
    min_pct = min(pct, na.rm = TRUE),
    max_pct = max(pct, na.rm = TRUE),
    sd_pct = sd(pct, na.rm = TRUE)
  )

# Combine the summaries
combined_summary <- bind_rows(trump_summary, harris_summary)

# Display the table
knitr::kable(combined_summary, col.names = c("Candidate", "Mean %", "Median %", "Min %", "Max %", "SD %"))

```
To understand the factors that influence this outcome, we include several predictor variables. The pollster variable identifies each polling organization, acknowledging that different pollsters may produce slightly different results due to unique methodologies and respondent demographics. Numerical poll scores provide a quality rating for each poll, with higher scores indicating greater credibility and predictive reliability. These variables ensure that only reliable sources influence our analysis of Trump's approval rating. The methodology and transparency scores reflect the transparency of each poll's survey methodology and reporting, respectively. Different methodologies, such as online panels or telephone surveys, may affect response patterns, while transparency scores indicate reliability, providing further context for accurately interpreting support levels.

Time and region data are also critical in our analysis. The start and end dates provide a timeline of the polling period, allowing us to observe trends in public opinion as it change over time. The state variable captures the geographic focus of each poll, as table @tbl-state-mean-pct shows which help us identify regional differences in Trump’s support. Finally, the candidate name variable specifies Trump as the focal candidate, ensuring that we accurately measure support for his candidacy alone. 
```{r}
#| label: tbl-state-mean-pct
#| tbl-cap: "Preview of States Statistics for Trump and Harris"
#| echo: false
#| warning: false
#| message: false

# Combine Trump and Harris data with an identifying column for each candidate
combined_data <- trump_analysis_data %>%
  mutate(Candidate = "Trump") %>%
  bind_rows(harris_analysis_data %>% mutate(Candidate = "Harris"))

# Calculate mean percentage by state for each candidate, round to 2 decimal places, and display side-by-side
state_summary <- combined_data %>%
  group_by(state, Candidate) %>%
  summarise(mean_pct = round(mean(pct, na.rm = TRUE), 2)) %>%  # Round to 2 decimal places
  ungroup() %>%
  pivot_wider(names_from = Candidate, values_from = mean_pct, values_fill = 0) %>%
  rename("Harris %" = Harris, "Trump %" = Trump) %>%
  filter(`Harris %` > 0 & `Trump %` > 0)  # Filter rows where both percentages are non-zero

# Display the table with Harris and Trump in separate columns
knitr::kable(state_summary, col.names = c("State", "Harris %", "Trump %"))


```





# Model {#sec-model}

```{r}
#modelsummary(models = list("Model 1" = model_date, "Model 2" = model_date_pollster))

#model_date <- 
  #readRDS(file = here::here("models/model_date.rds"))
#model_date_pollster <- 
   #readRDS(file = here::here("models/model_date_pollster.rds"))

```

### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results {#sec-result}

Our results are summarized in 




# Discussion {#sec-discussion}

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

# Weaknesses and next steps  {#sec-limitation}

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}
Polling Methodology for CBS News/YouGov Survey (October 11-16, 2024)

1. Population, Frame, and Sample
This CBS News/YouGov survey took place from October 11-16, 2024, with 1,439 registered voters in Arizona. The survey focused on registered voters in Arizona, and the sample was weighted to match key demographics like gender, age, race, and education. The weights were based on data from the U.S. Census American Community Survey, the U.S. Census Current Population Survey, and voter turnout data from the 2020 Presidential election.

2. Sample Recruitment
The recruitment process focused on including respondents representative of Arizona's registered voter population by adjusting for demographic factors such as age, race, gender, and education.
The sample was recruited primarily from various online panels, which included a mixture of respondents across demographic lines, to ensure a representative sample:
	1,152 respondents were selected from YouGov’s online panel.
	212 respondents from Pure Spectrum’s panel.
	49 respondents from Dynata.
	17 respondents from Cint’s panel.
	9 respondents from ROI Rocket’s panel.

Surveys were conducted in both English and Spanish to account for language preferences among respondents. The weights applied to the data ranged from 0.1 to 5.0, with a mean of 1 and a standard deviation of 0.8, ensuring that the sample was representative of Arizona’s voting population.

3. Sampling Approach and Trade-offs
Sampling Approach: This survey employed stratified random sampling and applied
post-survey weighting to ensure accurate representation of key demographic groups. Stratified random sampling is a technique that divides the overall population into several subgroups (or strata) based on specific attributes such as age, gender, race, and education level. Random samples are then drawn from each subgroup. The advantage of this method is that it ensures adequate representation across each stratum, preventing certain groups from being underrepresented or overlooked in the sample.
After the survey was completed, weighting was applied to further adjust the sample to match the demographic distribution of registered voters in Arizona. This process involved adjusting the weights of individuals in the sample to better reflect the true composition of the overall voter population. This allows for a more accurate capture of how different demographic factors (such as gender, age, race, and education) influence voting behavior, thereby improving the external validity of the results.
By using stratified random sampling and weighting, the researchers were able to minimize sampling bias and increase the accuracy of predicting voter tendencies.
Trade-offs: One of the main limitations of this sampling method is its reliance on online panels, which may exclude individuals without internet access, thus introducing selection bias. While online surveys are cost-effective and convenient for collecting large samples, this reliance may result in certain groups (such as older individuals, low-income households, or voters living in remote areas) being left out due to lack of internet access. This means that some groups might be underrepresented in the sample, which can affect the overall representativeness of the results.
Although the weighting process can help adjust the sample to better reflect demographic differences, some errors are still difficult to completely eliminate. For example, when filling out surveys, respondents might overstate or understate their voting intentions due to social pressure or personal emotions—this is known as self-reporting bias. Even after weighting adjustments, such biases may persist and impact the accuracy of the final survey results.
Therefore, while weighting can improve the representativeness of the results to a certain extent, systematic biases like non-response bias or selection bias may still leave traces in the final outcomes. Researchers need to interpret these potential errors with caution.

4. Regression Model
A regression model was used to estimate each respondent’s likelihood of voting. This model combined self-reported voting intentions with demographic and historical voting data, such as:
	Age, gender, race, and education.
	Voting history from past elections.
The regression model allowed the survey to distinguish "likely voters" from the broader pool of registered voters, improving the accuracy of the predictions. By analyzing both individual and aggregate data, the model offered a more reliable estimate of actual voter turnout, thus increasing the precision of the survey’s results.

5. Handling Non-response
In surveys, non-response can cause bias because these people might have different voting behaviors or opinions. To fix this potential bias, researchers use weighting to adjust the sample data. Specifically, they assign different weights to respondents based on key demographic factors like gender, age, race, and education.
The main goal of this weighting process is to make sure that even if some voters didn’t respond, the final sample still accurately represents the overall population of registered voters in Arizona. This adjustment helps make the sample more representative and reduces the bias caused by non-response, improving the reliability and accuracy of the survey results.
Besides that, weighting helps balance the proportion of different groups in the sample, ensuring that certain groups (like those with less access to the internet) are properly reflected in the results. In the end, this process helps make sure the survey results are more valid and can be applied more effectively to predict real voter behavior.

6. Strengths and Weaknesses of the Questionnaire
Strengths: This survey effectively covered the key issues that Arizona voters care about the most, such as the economy, immigration, abortion, and the state of democracy. By combining demographic factors and historical voting data, the reliability of the results was improved, making it more accurate in reflecting the voting preferences of different groups.
Weaknesses: Since the survey relies on self-reported voting intentions, this might introduce some bias, as respondents could overestimate or underestimate their likelihood of voting. Also, because it depends on online panels, voters without internet access may have been excluded, which could affect the external validity of the results. The margin of error is ±3.3 points, showing that there’s still some uncertainty in the findings.

7. Margin of Error
The margin of error for this survey is ±3.3 points, within a 95% confidence interval. The formula to calculate the margin of error is:
p ̂± 100 × √((1+CV^2)/n)
Where CV is the coefficient of variation of the sample weights, and \( n \) is the sample size. This formula calculates the sampling error, meaning that 95% of the sample results should fall within this range. It’s important to note that this margin doesn’t account for non-sampling errors, such as biases from panel selection or respondent behavior.


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 



## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...




\newpage


# References


